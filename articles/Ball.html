<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Ball: Statistical Inference and Sure Independence Screening via Ball Statistics • Ball</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Ball: Statistical Inference and Sure Independence Screening via Ball Statistics">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">Ball</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.3.14</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/Ball.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/bd_gwas.html">`bd.gwas.test`: Fast Ball Divergence Test for Multiple Hypothesis Tests</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/Mamba413/Ball/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Ball: Statistical Inference and Sure Independence Screening via Ball Statistics</h1>
                        <h4 data-toc-skip class="author">Jin Zhu, <a href="mailto:zhuj37@mail2.sysu.edu.cn" class="email">zhuj37@mail2.sysu.edu.cn</a>
</h4>
            
            <h4 data-toc-skip class="date">December 18, 2017</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/Mamba413/Ball/tree/master/R-package/vignettes/Ball.Rmd" class="external-link"><code>vignettes/Ball.Rmd</code></a></small>
      <div class="d-none name"><code>Ball.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="quick-start">Quick Start<a class="anchor" aria-label="anchor" href="#quick-start"></a>
</h2>
<p>The fundamental problems for data mining and statistical analysis
are:</p>
<ol style="list-style-type: decimal">
<li><p>Whether distributions of two samples are distinct?</p></li>
<li><p>Whether two random variables are dependent?</p></li>
</ol>
<p>Two-sample test, which is designed to solve the first problem, is
very important in medicine, psychology, biology and so on. For instance,
we want to know whether lifespan of male and female is different. Thus,
we collect lifetime data, and try to figure out whether ages in two
samples are identically distributed. As the following images shown, if
distribution of life span in two groups look like the left one, we
conclude that lifetime are not identically distributed. But for the
right one, it indicates that they are most likely to be identically
distributed.</p>
<div class="float">
<img src="classificationDemo.png" alt="Figure 1"><div class="figcaption">Figure 1</div>
</div>
<p>Test of independence, which is designed to solve the other problem,
is also very essential. As the following images shown, there is a strong
linear relation with Y and X1, while X2 seems to have nothing to do with
Y. So X1 should be taken into account and added in to the regression
model for Y, or should be studied carefully in order to confirm the
correlation mechanism with Y.</p>
<div class="float">
<img src="regressionDemo.png" alt="Figure 2"><div class="figcaption">Figure 2</div>
</div>
<p><strong>Ball</strong> package provides solution for independence
test, two-sample test or even K-sample test. Moreover, a generic
non-parametric sure independence screening procedure also implemented to
deal with ultra high dimensional data.</p>
<p>The three core functions are:</p>
<ul>
<li><p><strong>bd.test</strong>: examine whether
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>K</mi><mo>≥</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">K(K \geq 2)</annotation></semantics></math>
univariate or multivariate distributions are identical.</p></li>
<li><p><strong>bcov.test</strong>: test whether univariate or
multivariate variables are related to each other.</p></li>
<li><p><strong>bcorsis</strong>: carry out sure independence screening
procedure to pick out the variables potentially related to
response.</p></li>
</ul>
<div class="section level4">
<h4 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h4>
<div class="section level5">
<h5 id="cran-version">CRAN version<a class="anchor" aria-label="anchor" href="#cran-version"></a>
</h5>
<p>To install the Ball R package from CRAN, just run:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"Ball"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level5">
<h5 id="github-version">Github version<a class="anchor" aria-label="anchor" href="#github-version"></a>
</h5>
<p>To install the development version from GitHub, run:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://devtools.r-lib.org/" class="external-link">devtools</a></span><span class="op">)</span></span>
<span><span class="fu">install_github</span><span class="op">(</span><span class="st">"Mamba413/Ball"</span>, build_vignettes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><em>Windows</em> user will need to install <a href="https://cran.r-project.org/bin/windows/Rtools/" class="external-link">Rtools</a>
first.</p>
</div>
</div>
<div class="section level4">
<h4 id="quick-start-univariate-two-sample-test">Quick Start: Univariate Two-sample Test<a class="anchor" aria-label="anchor" href="#quick-start-univariate-two-sample-test"></a>
</h4>
<p>In this example, we generate two normal random variables with
different location parameter:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mi>Y</mi><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X \sim N(0,1), Y \sim N(1, 1)</annotation></semantics></math><!-- In the mean time, we use the non-parametric kernel density estimation to plot the kernel density of two distribution: --></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span>, mean <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co"># plot(density(x), xlim = c(-5, 5))</span></span>
<span><span class="co"># lines(density(y), col = 'red')</span></span></code></pre></div>
<!-- ![](QuickStartUBD.png) -->
<p>We use <strong>bd.test</strong> to perform the two-sample test to
determine whether two samples come from the same distribution.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## TOFIX</span></span>
<span><span class="co"># bd.test(x = x, y = y)</span></span></code></pre></div>
<p>The result of <strong>bd.test</strong> is that <em>p</em>-value &lt;
0.05, which means to reject the null hypothesis, and conclude that two
samples are come from different distribution. Consequently, the
hypothesis test result is concordant to data generation mechanism.</p>
</div>
<div class="section level4">
<h4 id="quick-start-multivariate-two-sample-test">Quick Start: Multivariate Two-sample Test<a class="anchor" aria-label="anchor" href="#quick-start-multivariate-two-sample-test"></a>
</h4>
<p>In this example, we will demonstrate how to perform a test of whether
two multivariate distributions are identical. We generate two random
samples of size 50, which are sampled from two different multivariate
normal distributions:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><mi>X</mi></msub><mo>,</mo><msub><mi>I</mi><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mi>Y</mi><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo>,</mo><msub><mi>I</mi><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X \sim N(\mu_{X},I_{2 \times 2}), Y \sim N(\mu_{Y}, I_{2 \times 2})</annotation></semantics></math><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mi>X</mi></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu_{X} = (0,0), \mu_{Y} = (1,1)</annotation></semantics></math><!-- Then we will show the difference between these two samples in the way of kernel density estimation: --></p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">50</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, mean <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">50</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<!-- ![](./QuickStartBD.png) -->
<p>We use <strong>bd.test</strong> to test whether two multivariate
random samples are identically distributed.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   2-sample Ball Divergence Test (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  x and y </span></span>
<span><span class="co"># number of observations = 100, group sizes: 50 50</span></span>
<span><span class="co"># replicates = 99, weight: constant</span></span>
<span><span class="co"># bd.constant = 0.56944, p-value = 0.01</span></span>
<span><span class="co"># alternative hypothesis: distributions of samples are distinct</span></span></code></pre>
<p>The result of <strong>bd.test</strong> is that <em>p</em>-value &lt;
0.05, so we conclude that two samples are not identically
distributed.</p>
</div>
<div class="section level4">
<h4 id="quick-start-univariate-test-of-independence">Quick Start: Univariate Test of Independence<a class="anchor" aria-label="anchor" href="#quick-start-univariate-test-of-independence"></a>
</h4>
<p>In this example, we will use the “W-shape” data from <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence" class="external-link">WIKI</a>
to demonstrate how to perform univariate test of independence with
<strong>bcov.test</strong> .</p>
<p>We generate a dataset containing 50 samples.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># generate random perturbation:</span></span>
<span><span class="va">noise</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">50</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.3</span>, max <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">0</span>, <span class="fl">4</span><span class="op">*</span><span class="va">pi</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">cos</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="va">noise</span></span>
<span><span class="co"># plot(x, y)</span></span></code></pre></div>
<!-- From the plot we can see that $X$ has complex non-linear relation with Y. -->
<p>Obviously,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is related to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>,
but the relationship is non-linear. We use <strong>bcov.test</strong> to
perform the test of independence between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   Ball Covariance test of independence (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  x and y</span></span>
<span><span class="co"># number of observations = 50</span></span>
<span><span class="co"># replicates = 99, weight: constant</span></span>
<span><span class="co"># bcov.constant = 0.0025823, p-value = 0.01</span></span>
<span><span class="co"># alternative hypothesis: random variables are dependent</span></span></code></pre>
<p>The result of <strong>bcov.test</strong> is that <em>p</em>-value
&lt; 0.05, so we conclude that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
are not independent, which means there is some kind of correlation
between X and Y.</p>
</div>
<div class="section level4">
<h4 id="quick-start-multivariate-test-of-independence">Quick Start: Multivariate Test of Independence<a class="anchor" aria-label="anchor" href="#quick-start-multivariate-test-of-independence"></a>
</h4>
<p>For multivariate independence test, we will demonstrate the usage of
<strong>bcov.test</strong> with the following example:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X=(x_{1}, x_{2})</annotation></semantics></math>
come from the bivariate normal distribution. The relation between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is:<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mn>2</mn><mo>sin</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>ϵ</mi><mo>,</mo><mspace width="1.0em"></mspace><mi>ϵ</mi><mo>∼</mo><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mn>0.1</mn><mo>,</mo><mn>0.1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Y=2\sin(x_{1} + x_{2})+ \epsilon, \quad \epsilon \sim U(-0.1, 0.1)</annotation></semantics></math></p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">50</span> <span class="op">*</span> <span class="fl">2</span>, <span class="op">-</span><span class="va">pi</span>, <span class="va">pi</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">50</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">noise</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">50</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span>, max <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="va">noise</span></span></code></pre></div>
<!-- The following image shows the distribution of the data: -->
<!-- ![](QuickStartBCov.png) -->
<p>We use <strong>bcov.test</strong> to perform multivariate
independence test:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, weight <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   Ball Covariance test of independence (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  x and y</span></span>
<span><span class="co"># number of observations = 50</span></span>
<span><span class="co"># replicates = 99, weight: probability</span></span>
<span><span class="co"># bcov.probability = 0.038322, p-value = 0.04</span></span>
<span><span class="co"># alternative hypothesis: random variables are dependent</span></span></code></pre>
<p>The result of <strong>bcov.test</strong> is that <em>p</em>-value
&lt; 0.05, so we conclude that multivariate random variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
are associated.</p>
<!-- *** -->
<!-- # Introduction           -->
<!-- ### Ball Divergence        -->
<!-- We want to determine whether distributions of two samples $\mathcal{X} = \lbrace x_{1},...,x_{n} \rbrace$ and $\mathcal{Y} = \lbrace y_{1},...,y_{m} \rbrace$ are distinct.         -->
<!-- Intuitively, if $\mathcal{X}$ and $\mathcal{Y}$ come from identical distribution and we use any two points $x_{i}, x_{j} \in \mathcal{X}$ to construct a ball, then the ratio that elements of $\mathcal{X}$ and $\mathcal{Y}$ in the ball will be close to each other, which means: -->
<!-- $$A^{X}_{ij}  \approx A^{Y}_{ij}$$ -->
<!-- $$A^{X}_{ij} = \frac{1}{n}\sum_{u=1}^{n}{I(x_{u} \in \bar{B}(x_{i}, \rho(x_{i}, x_{j}))}$$ -->
<!-- $$A^{Y}_{ij} = \frac{1}{m}\sum_{v=1}^{m}{I(y_{v} \in \bar{B}(x_{i}, \rho(x_{i}, x_{j}))}$$ -->
<!-- where $\bar{B}(x_{i}, \rho(x_{i}, x_{j}))$ is a closed ball with center $x_{i}$, -->
<!-- and radius $\rho(x_{i}, x_{j})$ and $I$ is indicator function. -->
<!-- ![](BDPlot.jpeg) -->
<!-- In a similar way, for any two points $y_{i}, y_{j} \in \mathcal{Y}$, -->
<!-- they should also have the property: -->
<!-- $$C^{X}_{ij} \approx C^{Y}_{ij}$$ -->
<!-- $$C^{X}_{ij} = \frac{1}{n}\sum_{u=1}^{n}{I(x_{u} \in \bar{B}(y_{i}, \rho(y_{i}, y_{j}))}$$ -->
<!-- $$C^{Y}_{ij}=\frac{1}{m}\sum_{v=1}^{m}{I(y_{v} \in \bar{B}(y_{i}, \rho(y_{i}, y_{j}))}$$ -->
<!-- We combine the difference between $A^{X}_{ij}, A^{Y}_{ij}$ and the difference between -->
<!-- $C^{X}_{ij}, C^{Y}_{ij}$ together in the following way: -->
<!-- $$D_{n,m} = A_{n,m} + C_{n,m}$$  -->
<!-- where: -->
<!-- $$A_{n,m} = \frac{1}{n^{2}}\sum_{i,j=1}^{n}{(A_{ij}^{X}-A_{ij}^{Y})^{2}}$$ $$C_{n,m}=\frac{1}{m^{2}}\sum_{k,l=1}^{m}{(C_{kl}^{X}-C_{kl}^{Y})^{2}}$$ -->
<!-- $D_{n,m}$ is the sample version of Ball Divergence, defined by Pan et.al(2017). Techinical proofs provided by Pan et.al ensure $D_{n, m}$ converges to $D(\mu, \nu)$ when $n, m$ increase to infinity so long as:  -->
<!-- $$\frac{n}{m+n} \to \tau, \tau \in [0, 1].$$       -->
<!-- [Pan et al. (2017)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwjBvbb7gdTWAhUEoZQKHYvODxkQFggmMAA&url=https%3A%2F%2Fwww.e-publications.org%2Fims%2Fsubmission%2FAOS%2Fuser%2FsubmissionFile%2F24632%3Fconfirm%3D9219c1d0&usg=AOvVaw3I3Tad92DvETqhJEnJ7FyN) had proven that sample version of ball divergence $D(\mu, \nu) \geq 0$ where the equality holds if and only if $\mu=\nu$ where $\mu, \nu$ are induced measure corresponding to distribution of sample $\mathcal{X}$ and $\mathcal{Y}$. Theory and numerical result guarantee Two-Sample Test based on ball divergence have following advantages:         -->
<!-- - It is applicable to the univariate or multivariate data in Banach Space.             -->
<!-- - Robust to heavy-tail data or outliers.        -->
<!-- - Cope well for imbalanced data.        -->
<!-- - Works fine for most problems without tuning a variety of parameters.       -->
<!-- ### Ball Covariance                  -->
<!-- Investigate the dependence between variables is a fundamental step in statistical inference and data mining. Suppose, We are given pairs of independent observations $\{(x_1, y_1),\ldots,(x_n,y_n)\}$, where $x_i$ and $y_i$  can be of any dimension and the dimensionality of $x_i$ and $y_i$ need not be the same. Let $X = (x_1,\ldots,x_n)$ be the $X$ vector, and $Y=(y_1,\ldots,y_n)$ the  -->
<!-- $Y$ vector and we want to determine whether $X$ and $Y$ are dependent. -->
<!-- <!-- , which means whether $F_{XY}=F_{X}F_{Y}$ is valid or not. Where $F_{XY}$ is the joint distribution function of $X, Y$. -->
<!-- To achieve the goal, we come up with **Ball Covariance** ($\mathbf{BCor}_{\omega, n}^{2}$), a generic measure of dependence in banach space. Moreover, the $\mathbf{BCor}_{\omega, n}^{2}$ based independence test utilized permutation technique to calculate *p*-value is also developed. Sample version of $\mathbf{BCor}_{\omega, n}^{2}$ is defined as follow:          -->
<!-- $$\mathbf{BCor}_{\omega, n}^{2}(X, Y)=\frac{1}{n^{2}}\sum_{i,j=1}^{n}{(\Delta_{ij,n}^{X,Y}-\Delta_{ij,n}^{X}\Delta_{ij,n}^{Y})^{2}}\hat{\omega}_1(X_i,X_j)\hat{\omega}_2(Y_i,Y_j)$$ -->
<!-- where: -->
<!-- $$ \Delta_{ij,n}^{X,Y}=\frac{1}{n}\sum_{k=1}^{n}{\delta_{ij,k}^{X} \delta_{ij,k}^{Y}}$$ -->
<!-- $$\Delta_{ij,n}^{X}=\frac{1}{n}\sum_{k=1}^{n}{\delta_{ij,k}^{X}},  -->
<!-- \Delta_{ij,n}^{Y}=\frac{1}{n}\sum_{k=1}^{n}{\delta_{ij,k}^{Y}} $$ -->
<!-- $$ \delta_{ij,k}^{X} = I(x_{k} \in \bar{B}(x_{i}, \rho(x_{i}, x_{j})))$$ -->
<!-- $$\delta_{ij,k}^{Y} = I(y_{k} \in \bar{B}(y_{i}, \rho(y_{i}, y_{j})))$$ -->
<!-- Generally, we define $\hat{\omega}_1(X_i,X_j) = \hat{\omega}_2(Y_i,Y_j) = 1$, and simplify the notation $\mathbf{BCor}^{2}_{\omega, n}$ as $\mathbf{BCor}^{2}_{n}$ -->
<!-- ![](./BCovPlot.jpeg) -->
<!-- As the image above shown, the joint probability that $X, Y$ are both in the ball are intuitively closed to the product of marginal probability that $X$ and $Y$ are in the ball when $X$ and $Y$ are independent,  i.e.: -->
<!-- $$\Delta_{ij,n}^{X,Y} \approx \Delta_{ij,n}^{X}\Delta_{ij,n}^{Y}$$ -->
<!-- Consequently, if $\mathbf{BCor}_{\omega, n}^{2}$ is significantly larger than 0, then it indicates that $X$ and $Y$ are not independent. -->
<!-- As Pan's paper proved theoretically and demonstrated numerically, the independence test based on $\mathbf{BCor}_{\omega, n}^{2}$ has several advantages: -->
<!-- - It is applicable to the univariate and multivariate data in banach space.       -->
<!-- - Robust to heavy-tail data or outliers         -->
<!-- - Works fine for most problems without tuning a variety of parameters.          -->
<!-- *** -->
</div>
</div>
<div class="section level2">
<h2 id="advance-features">Advance Features<a class="anchor" aria-label="anchor" href="#advance-features"></a>
</h2>
<p>The features below have been implemented to help you analyse diverse
and complicated real data.</p>
<div class="section level3">
<h3 id="non-hilbert-space-data">Non-Hilbert Space Data<a class="anchor" aria-label="anchor" href="#non-hilbert-space-data"></a>
</h3>
<p>During the scientific research, we always have to deal with
Non-Hilbert space data. However, the traditional statistical inference
methods usually depend on some assumptions, which are not able to
perform statistical inference on this kind of data directly. Whereas
ball divergence doesn’t depend on the assumptions needed in traditional
statistical inference method, and it’s able to perform two-sample test
for data from Non-Hilbert space. We will demonstrate how to use
<strong>Ball</strong> package to perform statistical inference for data
from Non-Hilbert space with three examples:</p>
<div class="section level5">
<h5 id="example-1-simulated-von-mises-fisher-distribution-data">Example 1: Simulated von Mises-Fisher distribution data<a class="anchor" aria-label="anchor" href="#example-1-simulated-von-mises-fisher-distribution-data"></a>
</h5>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load data:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"bdvmf"</span><span class="op">)</span></span></code></pre></div>
<p>The distribution of the data is shown in the following image:</p>
<p><img src="BDVmf.png"></p>
<p>In the image, the black dots
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>)
and red dots
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>)
respectively represent two group of simulated data with different
distributions. The distributions are denoted by:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∼</mo><mi>M</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><mi>X</mi></msub><mo>,</mo><mi>κ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mi>Y</mi><mo>∼</mo><mi>M</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo>,</mo><mi>κ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">X \sim M(\mu_{X}, \kappa), Y \sim M(\mu_{Y}, \kappa)</annotation></semantics></math>
Where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
denotes <a href="https://en.wikipedia.org/wiki/Von_Mises%E2%80%93Fisher_distribution" class="external-link">von
Mises-Fisher distribution</a>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mi>X</mi></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu_{X} = (1, 0, 0), \mu_{Y} = (1, 1, 1)</annotation></semantics></math>
are the orientation parameter of von Mises-Fisher distribution,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>κ</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\kappa = 3</annotation></semantics></math>
denotes aggregation parameter.</p>
<p>We can tell from the image that, red dots and black dots are not
identically distributed. However, it is a tough task for the traditional
statistical method to distinguish distribution because it is not a
conventional data in Hilbert space. Fortunately, since the computation
for sample version of ball divergence (ball covariance) only involves
calculate distance matrix and counting the number of samples located in
a ball, we can obtain empirical ball divergence so long as we can define
the distance metric between observations. Therefore, ball divergence
still work for this example.</p>
<p>We apply ball divergence to this data by carrying out the following
step. First, we calculate the geodesic distance matrix of the data,
which have been implemented in function . Later, we pass the distance
matrix to arguments and let , , and . The detailed solution is
demonstrated below:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># calculate geodesic distance between samples:</span></span>
<span><span class="va">dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">bdvmf</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"geodesic"</span><span class="op">)</span></span>
<span><span class="co"># sample sizes in each group: 150, 150</span></span>
<span><span class="co"># Two-Sample Test based on BD :</span></span>
<span><span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dx</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">150</span>, <span class="fl">150</span><span class="op">)</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, distance <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   2-sample Ball Divergence Test (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  dx </span></span>
<span><span class="co"># number of observations = 300, group sizes: 150 150</span></span>
<span><span class="co"># replicates = 99, weight: constant</span></span>
<span><span class="co"># bd.constant = 0.14483, p-value = 0.01</span></span>
<span><span class="co"># alternative hypothesis: distributions of samples are distinct</span></span></code></pre>
<p>In this example, we firstly calculate the geodesic distance matrix
using <strong>nhdist</strong> function in <em>Ball</em> package. Then,
pass <em>dx</em> to arguments <em>x</em> and set <em>distance =
TRUE</em> to indicate that the <em>x</em> parameter is a distance
matrix. Meanwhile, we set the size of each sample <em>size = c(150,
150)</em> and set the replication times <em>num.permutations = 99</em>.
The result is that <em>p</em>-value &lt; 0.05, which means that red dots
and black dots are not identically distributed.</p>
</div>
<div class="section level5">
<h5 id="example-2-macaques-data">Example 2: Macaques Data<a class="anchor" aria-label="anchor" href="#example-2-macaques-data"></a>
</h5>
<p>Based on Macaques data provided by dryden, scientists want to figure
out whether there are differences in the shape of skull between Macaques
of different genders. In a similar way, we can calculate the distance
matrix of the data and transform this problem into two-sample test that
can be solved by BD. Riemann shape distance is always used to describe
the distance between shape data. By setting <em>method = “riemann”</em>
in the <strong>nhdist</strong> function, we are able to calculate the
riemann shape distance between shape data. The detailed procedure is
demonstrated below:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load data:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"macaques"</span><span class="op">)</span></span>
<span><span class="co"># number of femala and male Macaca fascicularis:</span></span>
<span><span class="co"># table(macaques[["group"]])  # f: 9; m: 9</span></span>
<span><span class="co"># calculate Riemannian shape distance matrix:</span></span>
<span><span class="va">dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">macaques</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"riemann"</span><span class="op">)</span></span>
<span><span class="co"># hypothesis test with BD:</span></span>
<span><span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dx</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">9</span>, <span class="fl">9</span><span class="op">)</span>, distance <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   2-sample Ball Divergence Test (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  dx </span></span>
<span><span class="co"># number of observations = 18, group sizes: 9 9</span></span>
<span><span class="co"># replicates = 99, weight: constant</span></span>
<span><span class="co"># bd.constant = 0.1922, p-value = 0.03</span></span>
<span><span class="co"># alternative hypothesis: distributions of samples are distinct</span></span></code></pre>
<p><em>p</em>-value is under 0.05, which means the skull shape differs
between male macaques and female macaques.</p>
</div>
<div class="section level5">
<h5 id="example-3-arcticlake-data">Example 3: ArcticLake Data<a class="anchor" aria-label="anchor" href="#example-3-arcticlake-data"></a>
</h5>
<p><strong>bcov.test</strong> is related to calculating the distance
between samples of two multivariate random variables. Therefore, we can
examine independence assumption by employing <strong>bcov.test</strong>
to non-Hilbert space real data so long as we obtain the distance matrix
of the samples.</p>
<p>We take a data in the Book, <strong>The Statistical Analysis of
Compositional Data</strong>, as an example to demonstrate how to use
<strong>bcov.test</strong> to determine the dependence of non-Hilbert
space data. Scientists collect Sand, silt and clay compositions of 39
sediment samples of different water depth in an Arctic lake. They want
to figure out whether the compositions of sediment samples of different
water depth are identical or not. To achieve the goal, we use
<strong>bcov.test</strong> to perform the test of independence. The
detailed procedure is demonstrated below:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"ArcticLake"</span><span class="op">)</span></span>
<span><span class="co"># Distance matrix between y:</span></span>
<span><span class="va">dy</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"compositional"</span><span class="op">)</span></span>
<span><span class="co"># Distance matrix between x:</span></span>
<span><span class="va">dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html" class="external-link">dist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"depth"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co"># hypothesis test with BCov:</span></span>
<span><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dx</span>, y <span class="op">=</span> <span class="va">dy</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, distance <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   Ball Covariance test of independence (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  dx and dy</span></span>
<span><span class="co"># number of observations = 39</span></span>
<span><span class="co"># replicates = 99, weight: constant</span></span>
<span><span class="co"># bcov.constant = 0.0083848, p-value = 0.01</span></span>
<span><span class="co"># alternative hypothesis: random variables are dependent</span></span></code></pre>
<p>We first calculate the distance matrix <em>dy</em> and <em>dx</em>.
Then, we pass <em>dx</em> to arguments <em>x</em>, <em>dy</em> to
arguments <em>y</em>, and set the replication times <em>num.permutations
= 99</em>, <em>distance = TRUE</em> to indicate that the <em>x</em> and
<em>y</em> parameters are distance matrices.<br>
The result shows that <em>p</em>-value is less than 0.05, an usual
significance level, so we conclude that the compositions of sediment is
associated with the water depth.</p>
<p>In the example above, we use the square root transformed data to
calculate the geodesic distance as a measurement of the difference
between different compositions of sediment samples (<em>Dy</em>).
Meanwhile, we use euclidean distance to measure the difference of
different water depth (<em>Dx</em>). For different data, we can use
different measurements to cope with the different features in data.</p>
</div>
</div>
<div class="section level3">
<h3 id="k-sample-test">K-Sample Test<a class="anchor" aria-label="anchor" href="#k-sample-test"></a>
</h3>
<p><strong>bd.test</strong> is also applicable for testing of multiple
samples. We generate three random normal samples of size 50, which are
sampled from the same normal distribution. As an example, we use
<strong>bd.test</strong> to test whether these samples are identically
distributed.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">150</span></span>
<span><span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   3-sample Ball Divergence Test (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  rnorm(n) </span></span>
<span><span class="co"># number of observations = 150, group sizes: 50 50 50</span></span>
<span><span class="co"># replicates = 99, weight: constant, kbd.type: sum</span></span>
<span><span class="co"># kbd.sum.constant = 0.036419, p-value = 0.6</span></span>
<span><span class="co"># alternative hypothesis: distributions of samples are distinct</span></span></code></pre>
<p>As the result shown, <em>p</em>-value&gt;0.05, which means we can’t
reject the null hypothesis.<br>
We can also utilize <strong>bd.test</strong> to deal with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>-Sample
problem in non-Hilbert space following the aforementioned procedure. At
the same time, remember to assign size vector to parameter <em>size</em>
arguments and set <em>distance = TRUE</em>.</p>
<!-- Independent test based on ball correlation, which is a normalized coefficient of ball covariance also available now. Ball correlation statistic will be used when setting  -->
<!-- *type = "Bcor"* in **bcov.test**.          -->
</div>
<div class="section level3">
<h3 id="weighted-ball-covariance-test">Weighted Ball Covariance Test<a class="anchor" aria-label="anchor" href="#weighted-ball-covariance-test"></a>
</h3>
<!-- Moreover, we can extend defintion of $\hat{\omega}_1(X_i,X_j), \hat{\omega}_2(Y_i,Y_j)$. For example, we let: -->
<!-- $$\hat{\omega}_1(X_i,X_j) = \frac{1}{\rho(X_{i}, X_{j})}, \hat{\omega}_2(Y_i,Y_j) = \frac{1}{\rho(Y_{i}, Y_{j})}$$ -->
<!-- and calculate the weighted ball covariance:         -->
<!-- $$\mathbf{BCov}^2_{\omega,n}(\mathbf{X},\mathbf{Y}):=\frac{1}{n^2}\sum_{i,j=1}^{n}{(\Delta_{ij,n}^{X,Y}-\Delta_{ij,n}^{X}\Delta_{ij,n}^{Y})^2\hat{\omega}_1(X_i,X_j)\hat{\omega}_2(Y_i,Y_j)}$$ -->
<p>Pan et. al(2017) show that the weighted ball covariance based
independence test is statistical consistent against all dependence
alternatives without any moment conditions and some times superior to
standard version of ball covariance.</p>
<p>We have been implemented weighted ball covariance test in
<strong>Ball</strong> package and we can employ it to data analysis by
just setting <em>weight = TRUE</em> in <strong>bcov.test</strong>. Take
<em>ArcticLake</em> data as example:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"ArcticLake"</span><span class="op">)</span></span>
<span><span class="va">Dy</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"compositional"</span><span class="op">)</span></span>
<span><span class="va">Dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html" class="external-link">dist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"depth"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co"># hypothesis test with weighted BCov:</span></span>
<span><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Dx</span>, y <span class="op">=</span> <span class="va">Dy</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, </span>
<span>          distance <span class="op">=</span> <span class="cn">TRUE</span>, weight <span class="op">=</span> <span class="st">"constant"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   Ball Covariance test of independence (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  Dx and Dy</span></span>
<span><span class="co"># number of observations = 39</span></span>
<span><span class="co"># replicates = 99, weight: constant</span></span>
<span><span class="co"># bcov.constant = 0.0083848, p-value = 0.01</span></span>
<span><span class="co"># alternative hypothesis: random variables are dependent</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="ball-covariance-mutual-independence-test">Ball Covariance Mutual Independence Test<a class="anchor" aria-label="anchor" href="#ball-covariance-mutual-independence-test"></a>
</h3>
<p>Apart from the relationships between two random variables, another
important dependence concept for a set of variables is mutual (or joint)
independence, which says that any two disjoint subsets of variables are
independent from each other. For instance, we know to investigate
whether air temperature, soil temperature, humidity, wind and
evaporation are correlated.</p>
<p>It is natural to extend ball covariance to measure mutual
independence between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
random variables. <!-- as follows: -->
<!-- $$\mathbf{BCor}_{\omega, n}^{2}(R_{1}, ..., R_{K})=\frac{1}{n^{2}}\sum_{i,j=1}^{n}{(\Delta_{ij,n}^{R_{1}, ..., R_{K}}-\prod_{k=1}^{K}\Delta_{ij,n}^{R_{k}})^{2}\prod_{k=1}^{K}{\hat{\omega}_{k}(R_{ki},R_{kj})}}$$ -->
<!-- where $R_{k}, k=1,...K$ indicate random variables and $R_{ki}, i=1,...,n$ denote $n$ random samples of $R_{k}$.  -->
More importantly, Mutual independence test based on ball covariance have
been implemented in <strong>Ball</strong> package. We give two simply
example in the following to demonstrate its usage.</p>
<p>The first example,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>,</mo><msub><mi>ϵ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>ϵ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X, \epsilon_{1}, \epsilon_{2}</annotation></semantics></math>
are independent from the standard normal distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N(0,1)</annotation></semantics></math>,
and
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>ϵ</mi><mn>1</mn></msub><mo>,</mo><mspace width="0.278em"></mspace><mi>Z</mi><mo>=</mo><mo>min</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>ϵ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Y = \max(X, 0) + \epsilon_{1}, \; Z = \min(X, 0) + \epsilon_{2}</annotation></semantics></math></p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">example1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">z</span><span class="op">)</span></span></code></pre></div>
<p>The Second example,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>,</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo><mi>Z</mi></mrow><annotation encoding="application/x-tex">W, X, Y, Z</annotation></semantics></math>
are connected by a latent random variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H \sim N(0,1)</annotation></semantics></math>,
and
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msup><mi>H</mi><mn>2</mn></msup><mo>;</mo><mi>X</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">|</mo><mi>H</mi><mo stretchy="true" form="postfix">|</mo></mrow><mo>,</mo><mi>Y</mi><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>H</mi><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">W = H^{2}; X = |H|, Y = min(H, 0)</annotation></semantics></math><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Z</mi><mn>1</mn></msub><mo>,</mo><msub><mi>Z</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><msub><mi>Z</mi><mn>1</mn></msub><mo>=</mo><mi>I</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>H</mi><mo>&lt;</mo><mn>0.5</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>H</mi><mo>,</mo><msub><mi>Z</mi><mn>2</mn></msub><mo>=</mo><mi>I</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>H</mi><mo>&gt;</mo><mo>−</mo><mn>0.5</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">Z = (Z_{1}, Z_{2}), Z_{1}=I(H&lt;0.5)H, Z_{2}=I(H&gt;-0.5)H</annotation></semantics></math></p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">h</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">h</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">h</span> <span class="op">*</span> <span class="op">(</span><span class="va">h</span> <span class="op">&lt;</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">z1</span> <span class="op">&lt;-</span> <span class="va">h</span> <span class="op">*</span> <span class="op">(</span><span class="va">h</span> <span class="op">&lt;</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">z2</span> <span class="op">&lt;-</span> <span class="va">h</span> <span class="op">*</span> <span class="op">(</span><span class="va">h</span> <span class="op">&gt;</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">z1</span>, <span class="va">z2</span><span class="op">)</span></span>
<span><span class="va">example2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">w</span>, <span class="va">x</span>, <span class="va">y</span>, <span class="va">z</span><span class="op">)</span></span></code></pre></div>
<p>We bind these data to list <em>example1</em> and <em>example2</em>
and pass them to arguments <em>x</em> in <strong>bcov.test</strong> to
carry out ball covariance mutual independence test.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">example1</span>, num.permutations <span class="op">=</span> <span class="fl">199</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   Ball Covariance test of mutual independence (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  example1</span></span>
<span><span class="co"># number of observations = 50</span></span>
<span><span class="co"># replicates = 199, weight: constant</span></span>
<span><span class="co"># bcov.constant = 0.0021847, p-value = 0.005</span></span>
<span><span class="co"># alternative hypothesis: random variables are dependent</span></span></code></pre>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">example2</span>, num.permutations <span class="op">=</span> <span class="fl">199</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co"># </span></span>
<span><span class="co">#   Ball Covariance test of mutual independence (Permutation)</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># data:  example2</span></span>
<span><span class="co"># number of observations = 50</span></span>
<span><span class="co"># replicates = 199, weight: constant</span></span>
<span><span class="co"># bcov.constant = 0.034086, p-value = 0.005</span></span>
<span><span class="co"># alternative hypothesis: random variables are dependent</span></span></code></pre>
<p>The hypothesis test result for two examples show that
<em>p</em>-value &lt; 0.05, coinciding with the simulation setting.</p>
</div>
<div class="section level3">
<h3 id="ball-correlation-based-sure-independence-screening">Ball Correlation Based Sure Independence Screening<a class="anchor" aria-label="anchor" href="#ball-correlation-based-sure-independence-screening"></a>
</h3>
<p>Recent technological advances have made it possible to collect ultra
high-dimensional data. A common feature of these data is that the number
of variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
is generally much larger than sample sizes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>.
For instance, the number of gene expression profiles is in the order of
tens of thousands while the number of patient samples is in the order of
tens or hundreds. However, traditional variable selection algorithms
such as LASSO, SCAD may not perform well due to the statistical
inaccuracy, and algorithmic instability.</p>
<p>A new framework, sure independence screening (SIS), was proposed to
tackle the challenges above. SIS tries to filtering out the features
that have marginal correlation with the response, hence effectively
reducing the dimensionality
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
to a moderate scale so that performing statistical algorithm is
feasible.</p>
<p>BCor-SIS, a generic non-parametric sure independence screening
procedure based on ball correlation, is able to pick out explanatory
variables related to response. The linear, non-linear or linear
interaction effect relationship can be captured by BCor-SIS even though
data is heavy tail or existing outliers. More importantly, BCor-SIS is
able to retain all of the important features in the model with
probability tending to 1 under mild conditions.</p>
<div class="section level4">
<h4 id="bcor-sis-quick-start-example">BCor-SIS: Quick Start Example<a class="anchor" aria-label="anchor" href="#bcor-sis-quick-start-example"></a>
</h4>
<p>In this example, we will utilize <strong>bcorsis</strong> function to
carry out BCor-SIS procedure. We generate 150 high dimensional instances
with 3000 independent standard gaussian explanatory variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and univariate response variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>.
The relation between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is:<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mn>3</mn><msub><mi>X</mi><mn>1</mn></msub><mo>+</mo><mn>5</mn><msubsup><mi>X</mi><mn>3</mn><mn>2</mn></msubsup><mo>+</mo><mi>ϵ</mi><mo>,</mo><mspace width="1.0em"></mspace><mi>ϵ</mi><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Y=3 X_{1} + 5 X_{3}^{2} + \epsilon, \quad \epsilon \sim N(0, 1)</annotation></semantics></math></p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">150</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">3000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">noise</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">3</span><span class="op">*</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fl">5</span><span class="op">*</span><span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">noise</span></span></code></pre></div>
<p>We perform BCor-SIS procedure and display the top 5 variables index
selected by BCor-SIS.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## TOFIX</span></span>
<span><span class="co"># res &lt;- bcorsis(y = y, x = x)</span></span>
<span><span class="co"># head(res[[1]], n = 5)</span></span></code></pre></div>
<p>The <strong>bcorsis</strong> result shows that the first and the
third variable are the two most important variables in 3000 explanatory
variables which is consistent to simulation settings.</p>
</div>
<div class="section level4">
<h4 id="extension-of-bcor-sis-a-censored-survival-data">Extension of BCor-SIS: A Censored Survival Data<a class="anchor" aria-label="anchor" href="#extension-of-bcor-sis-a-censored-survival-data"></a>
</h4>
<p>Survival analysis is a commonly used method for the analysis of
censored data such as biological death and mechanical failure, which is
usually subject to censoring. The main goal of survival analysis is to
study the dependence of the survival time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>
on covariate variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>,</mo><mi>X</mi><mo>∈</mo><msup><mi>R</mi><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">X, X \in R^{p}</annotation></semantics></math>.</p>
<p>With the remarkable development of modern technology, a huge amount
of covariate information such as microarray and SNP data are collected.
Consequently, SIS procedure designed for censored survival data is in
need. Pan et al(2017) proposed a extend BCor-SIS procedure which is able
to selected the significant variables for censored data.</p>
<p>We implement BCor-SIS procedure for survival data in
<strong>Ball</strong> package and use a publicly lung cancer genomic
data from the Chemores Cohort Study to demonstrate its usage. The data
outcome was the “Disease-Free Survival Time”. Patients were followed
until the first relapse occurred or administrative censoring. In this
genomic dataset, the expression levels of mRNA, miRNA as well as
clinical variables from the 123 samples were included. Moreover, this
dataset include 944 biological covariates and 1056 artificial standard
gaussian variables which are independence with response. We employ
extension of Bcor-SIS on this data to hunt for efficient covariates and
demonstrate detailed procedure in the following.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## TOFIX</span></span>
<span><span class="co"># result &lt;- bcorsis(x = genlung[["covariate"]], </span></span>
<span><span class="co">#                   y = genlung[["survival"]], </span></span>
<span><span class="co">#                   d = "small", method = "survival")</span></span>
<span><span class="co"># top_gene &lt;- colnames(genlung[["covariate"]])[result[["ix"]]]</span></span>
<span><span class="co"># head(top_gene, n = 1)</span></span></code></pre></div>
<p>We first pass covariates and censored information to arugments
<em>x</em> and <em>y</em>, and set the <em>method = “survival”</em> to
indicate that the <em>y</em> should be considered as a survival status
containing event time and censored status. BCor-SIS asserts that
<em>hsa.miR.564</em>, corresponding to gene <em>MIR564</em>, is strongly
relevant to disease-free survival status. The conclusion is highly
coincident with the statement in other public literature.</p>
<!-- ### Reference -->
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Jin Zhu, Wenliang Pan, Junhao Zhu, Yuan Tian, Weinan Xiao, Chengfeng Liu, Ruihuang Liu, Yue Hu, Hongtu Zhu, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
