<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ball: Statistical Inference and Sure Independence Screening via Ball Statistics • Ball</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Ball: Statistical Inference and Sure Independence Screening via Ball Statistics">
<meta property="og:description" content="Ball">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">Ball</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.3.11</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/Ball.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/Mamba413/Ball/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="Ball_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Ball: Statistical Inference and Sure Independence Screening via Ball Statistics</h1>
                        <h4 class="author">Jin Zhu, <a href="mailto:zhuj37@mail2.sysu.edu.cn" class="email">zhuj37@mail2.sysu.edu.cn</a>
</h4>
            
            <h4 class="date">December 18, 2017</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/Mamba413/Ball/tree/master/R-package/../vignettes/Ball.Rmd"><code>../vignettes/Ball.Rmd</code></a></small>
      <div class="hidden name"><code>Ball.Rmd</code></div>

    </div>

    
    
<div id="quick-start" class="section level1">
<h1 class="hasAnchor">
<a href="#quick-start" class="anchor"></a>Quick Start</h1>
<p>The fundamental problems for data mining and statistical analysis are:</p>
<ol style="list-style-type: decimal">
<li><p>Whether distributions of two samples are distinct?</p></li>
<li><p>Whether two random variables are dependent?</p></li>
</ol>
<p>Two-sample test, which is designed to solve the first problem, is very important in medicine, psychology, biology and so on. For instance, we want to know whether lifespan of male and female is different. Thus, we collect lifetime data, and try to figure out whether ages in two samples are identically distributed. As the following images shown, if distribution of life span in two groups look like the left one, we conclude that lifetime are not identically distributed. But for the right one, it indicates that they are most likely to be identically distributed.</p>
<div class="figure">
<img src="classificationDemo.png" alt=""><p class="caption">Figure 1</p>
</div>
<p>Test of independence, which is designed to solve the other problem, is also very essential. As the following images shown, there is a strong linear relation with Y and X1, while X2 seems to have nothing to do with Y. So X1 should be taken into account and added in to the regression model for Y, or should be studied carefully in order to confirm the correlation mechanism with Y.</p>
<div class="figure">
<img src="regressionDemo.png" alt=""><p class="caption">Figure 2</p>
</div>
<p><strong>Ball</strong> package provides solution for independence test, two-sample test or even K-sample test. Moreover, a generic non-parametric sure independence screening procedure also implemented to deal with ultra high dimensional data.</p>
<p>The three core functions are:</p>
<ul>
<li><p><strong>bd.test</strong>: examine whether <span class="math inline">\(K(K \geq 2)\)</span> univariate or multivariate distributions are identical.</p></li>
<li><p><strong>bcov.test</strong>: test whether univariate or multivariate variables are related to each other.</p></li>
<li><p><strong>bcorsis</strong>: carry out sure independence screening procedure to pick out the variables potentially related to response.</p></li>
</ul>
<div id="installation" class="section level3">
<h3 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h3>
<div id="cran-version" class="section level4">
<h4 class="hasAnchor">
<a href="#cran-version" class="anchor"></a>CRAN version</h4>
<p>To install the Ball R package from CRAN, just run:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"Ball"</span><span class="op">)</span></code></pre></div>
</div>
<div id="github-version" class="section level4">
<h4 class="hasAnchor">
<a href="#github-version" class="anchor"></a>Github version</h4>
<p>To install the development version from GitHub, run:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">devtools</span><span class="op">)</span>
<span class="fu">install_github</span><span class="op">(</span><span class="st">"Mamba413/Ball"</span>, build_vignettes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<p><em>Windows</em> user will need to install <a href="https://cran.r-project.org/bin/windows/Rtools/">Rtools</a> first.</p>
</div>
</div>
<div id="quick-start-univariate-two-sample-test" class="section level3">
<h3 class="hasAnchor">
<a href="#quick-start-univariate-two-sample-test" class="anchor"></a>Quick Start: Univariate Two-sample Test</h3>
<p>In this example, we generate two normal random variables with different location parameter: <span class="math display">\[X \sim N(0,1), Y \sim N(1, 1)\]</span> <!-- In the mean time, we use the non-parametric kernel density estimation to plot the kernel density of two distribution: --></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span>, mean <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co"># plot(density(x), xlim = c(-5, 5))</span>
<span class="co"># lines(density(y), col = 'red')</span></code></pre></div>
<!-- ![](QuickStartUBD.png) -->
<p>We use <strong>bd.test</strong> to perform the two-sample test to determine whether two samples come from the same distribution.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   2-sample Ball Divergence Test (Permutation)
# 
# data:  x and y 
# number of observations = 100, group sizes: 50 50
# replicates = 99, weight: constant
# bd.constant = 0.092215, p-value = 0.01
# alternative hypothesis: distributions of samples are distinct</code></pre>
<p>The result of <strong>bd.test</strong> is that <em>p</em>-value &lt; 0.05, which means to reject the null hypothesis, and conclude that two samples are come from different distribution. Consequently, the hypothesis test result is concordant to data generation mechanism.</p>
</div>
<div id="quick-start-multivariate-two-sample-test" class="section level3">
<h3 class="hasAnchor">
<a href="#quick-start-multivariate-two-sample-test" class="anchor"></a>Quick Start: Multivariate Two-sample Test</h3>
<p>In this example, we will demonstrate how to perform a test of whether two multivariate distributions are identical. We generate two random samples of size 50, which are sampled from two different multivariate normal distributions: <span class="math display">\[X \sim N(\mu_{X},I_{2 \times 2}), Y \sim N(\mu_{Y}, I_{2 \times 2})\]</span> <span class="math display">\[\mu_{X} = (0,0), \mu_{Y} = (1,1)\]</span> <!-- Then we will show the difference between these two samples in the way of kernel density estimation: --></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">50</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, mean <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">50</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<!-- ![](./QuickStartBD.png) -->
<p>We use <strong>bd.test</strong> to test whether two multivariate random samples are identically distributed.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   2-sample Ball Divergence Test (Permutation)
# 
# data:  x and y 
# number of observations = 100, group sizes: 50 50
# replicates = 99, weight: constant
# bd.constant = 0.50074, p-value = 0.01
# alternative hypothesis: distributions of samples are distinct</code></pre>
<p>The result of <strong>bd.test</strong> is that <em>p</em>-value &lt; 0.05, so we conclude that two samples are not identically distributed.</p>
</div>
<div id="quick-start-univariate-test-of-independence" class="section level3">
<h3 class="hasAnchor">
<a href="#quick-start-univariate-test-of-independence" class="anchor"></a>Quick Start: Univariate Test of Independence</h3>
<p>In this example, we will use the “W-shape” data from <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">WIKI</a> to demonstrate how to perform univariate test of independence with <strong>bcov.test</strong> .</p>
<p>We generate a dataset containing 50 samples.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># generate random perturbation:</span>
<span class="va">noise</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">50</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.3</span>, max <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">0</span>, <span class="fl">4</span><span class="op">*</span><span class="va">pi</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="va">noise</span>
<span class="co"># plot(x, y)</span></code></pre></div>
<!-- From the plot we can see that $X$ has complex non-linear relation with Y. -->
<p>Obviously, <span class="math inline">\(X\)</span> is related to <span class="math inline">\(Y\)</span>, but the relationship is non-linear. We use <strong>bcov.test</strong> to perform the test of independence between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   Ball Covariance test of independence (Permutation)
# 
# data:  x and y
# number of observations = 50
# replicates = 99, weight: constant
# bcov.constant = 0.0023845, p-value = 0.01
# alternative hypothesis: random variables are dependent</code></pre>
<p>The result of <strong>bcov.test</strong> is that <em>p</em>-value &lt; 0.05, so we conclude that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not independent, which means there is some kind of correlation between X and Y.</p>
</div>
<div id="quick-start-multivariate-test-of-independence" class="section level3">
<h3 class="hasAnchor">
<a href="#quick-start-multivariate-test-of-independence" class="anchor"></a>Quick Start: Multivariate Test of Independence</h3>
<p>For multivariate independence test, we will demonstrate the usage of <strong>bcov.test</strong> with the following example: <span class="math inline">\(X=(x_{1}, x_{2})\)</span> come from the bivariate normal distribution. The relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is:<br><span class="math display">\[Y=2\sin(x_{1} + x_{2})+ \epsilon, \quad \epsilon \sim U(-0.1, 0.1)\]</span></p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">50</span> <span class="op">*</span> <span class="fl">2</span>, <span class="op">-</span><span class="va">pi</span>, <span class="va">pi</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">50</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">noise</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">50</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span>, max <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="va">noise</span></code></pre></div>
<!-- The following image shows the distribution of the data: -->
<!-- ![](QuickStartBCov.png) -->
<p>We use <strong>bcov.test</strong> to perform multivariate independence test:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, weight <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   Ball Covariance test of independence (Permutation)
# 
# data:  x and y
# number of observations = 50
# replicates = 99, weight: probability
# bcov.probability = 0.03935, p-value = 0.01
# alternative hypothesis: random variables are dependent</code></pre>
<p>The result of <strong>bcov.test</strong> is that <em>p</em>-value &lt; 0.05, so we conclude that multivariate random variable <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are associated.</p>
<!-- *** -->
<!-- # Introduction           -->
<!-- ### Ball Divergence        -->
<!-- We want to determine whether distributions of two samples $\mathcal{X} = \lbrace x_{1},...,x_{n} \rbrace$ and $\mathcal{Y} = \lbrace y_{1},...,y_{m} \rbrace$ are distinct.         -->
<!-- Intuitively, if $\mathcal{X}$ and $\mathcal{Y}$ come from identical distribution and we use any two points $x_{i}, x_{j} \in \mathcal{X}$ to construct a ball, then the ratio that elements of $\mathcal{X}$ and $\mathcal{Y}$ in the ball will be close to each other, which means: -->
<!-- $$A^{X}_{ij}  \approx A^{Y}_{ij}$$ -->
<!-- $$A^{X}_{ij} = \frac{1}{n}\sum_{u=1}^{n}{I(x_{u} \in \bar{B}(x_{i}, \rho(x_{i}, x_{j}))}$$ -->
<!-- $$A^{Y}_{ij} = \frac{1}{m}\sum_{v=1}^{m}{I(y_{v} \in \bar{B}(x_{i}, \rho(x_{i}, x_{j}))}$$ -->
<!-- where $\bar{B}(x_{i}, \rho(x_{i}, x_{j}))$ is a closed ball with center $x_{i}$, -->
<!-- and radius $\rho(x_{i}, x_{j})$ and $I$ is indicator function. -->
<!-- ![](BDPlot.jpeg) -->
<!-- In a similar way, for any two points $y_{i}, y_{j} \in \mathcal{Y}$, -->
<!-- they should also have the property: -->
<!-- $$C^{X}_{ij} \approx C^{Y}_{ij}$$ -->
<!-- $$C^{X}_{ij} = \frac{1}{n}\sum_{u=1}^{n}{I(x_{u} \in \bar{B}(y_{i}, \rho(y_{i}, y_{j}))}$$ -->
<!-- $$C^{Y}_{ij}=\frac{1}{m}\sum_{v=1}^{m}{I(y_{v} \in \bar{B}(y_{i}, \rho(y_{i}, y_{j}))}$$ -->
<!-- We combine the difference between $A^{X}_{ij}, A^{Y}_{ij}$ and the difference between -->
<!-- $C^{X}_{ij}, C^{Y}_{ij}$ together in the following way: -->
<!-- $$D_{n,m} = A_{n,m} + C_{n,m}$$  -->
<!-- where: -->
<!-- $$A_{n,m} = \frac{1}{n^{2}}\sum_{i,j=1}^{n}{(A_{ij}^{X}-A_{ij}^{Y})^{2}}$$ $$C_{n,m}=\frac{1}{m^{2}}\sum_{k,l=1}^{m}{(C_{kl}^{X}-C_{kl}^{Y})^{2}}$$ -->
<!-- $D_{n,m}$ is the sample version of Ball Divergence, defined by Pan et.al(2017). Techinical proofs provided by Pan et.al ensure $D_{n, m}$ converges to $D(\mu, \nu)$ when $n, m$ increase to infinity so long as:  -->
<!-- $$\frac{n}{m+n} \to \tau, \tau \in [0, 1].$$       -->
<!-- [Pan et al. (2017)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwjBvbb7gdTWAhUEoZQKHYvODxkQFggmMAA&url=https%3A%2F%2Fwww.e-publications.org%2Fims%2Fsubmission%2FAOS%2Fuser%2FsubmissionFile%2F24632%3Fconfirm%3D9219c1d0&usg=AOvVaw3I3Tad92DvETqhJEnJ7FyN) had proven that sample version of ball divergence $D(\mu, \nu) \geq 0$ where the equality holds if and only if $\mu=\nu$ where $\mu, \nu$ are induced measure corresponding to distribution of sample $\mathcal{X}$ and $\mathcal{Y}$. Theory and numerical result guarantee Two-Sample Test based on ball divergence have following advantages:         -->
<!-- - It is applicable to the univariate or multivariate data in Banach Space.             -->
<!-- - Robust to heavy-tail data or outliers.        -->
<!-- - Cope well for imbalanced data.        -->
<!-- - Works fine for most problems without tuning a variety of parameters.       -->
<!-- ### Ball Covariance                  -->
<!-- Investigate the dependence between variables is a fundamental step in statistical inference and data mining. Suppose, We are given pairs of independent observations $\{(x_1, y_1),\ldots,(x_n,y_n)\}$, where $x_i$ and $y_i$  can be of any dimension and the dimensionality of $x_i$ and $y_i$ need not be the same. Let $X = (x_1,\ldots,x_n)$ be the $X$ vector, and $Y=(y_1,\ldots,y_n)$ the  -->
<!-- $Y$ vector and we want to determine whether $X$ and $Y$ are dependent. -->
<!-- <!-- , which means whether $F_{XY}=F_{X}F_{Y}$ is valid or not. Where $F_{XY}$ is the joint distribution function of $X, Y$. -->
<!-- To achieve the goal, we come up with **Ball Covariance** ($\mathbf{BCor}_{\omega, n}^{2}$), a generic measure of dependence in banach space. Moreover, the $\mathbf{BCor}_{\omega, n}^{2}$ based independence test utilized permutation technique to calculate *p*-value is also developed. Sample version of $\mathbf{BCor}_{\omega, n}^{2}$ is defined as follow:          -->
<!-- $$\mathbf{BCor}_{\omega, n}^{2}(X, Y)=\frac{1}{n^{2}}\sum_{i,j=1}^{n}{(\Delta_{ij,n}^{X,Y}-\Delta_{ij,n}^{X}\Delta_{ij,n}^{Y})^{2}}\hat{\omega}_1(X_i,X_j)\hat{\omega}_2(Y_i,Y_j)$$ -->
<!-- where: -->
<!-- $$ \Delta_{ij,n}^{X,Y}=\frac{1}{n}\sum_{k=1}^{n}{\delta_{ij,k}^{X} \delta_{ij,k}^{Y}}$$ -->
<!-- $$\Delta_{ij,n}^{X}=\frac{1}{n}\sum_{k=1}^{n}{\delta_{ij,k}^{X}},  -->
<!-- \Delta_{ij,n}^{Y}=\frac{1}{n}\sum_{k=1}^{n}{\delta_{ij,k}^{Y}} $$ -->
<!-- $$ \delta_{ij,k}^{X} = I(x_{k} \in \bar{B}(x_{i}, \rho(x_{i}, x_{j})))$$ -->
<!-- $$\delta_{ij,k}^{Y} = I(y_{k} \in \bar{B}(y_{i}, \rho(y_{i}, y_{j})))$$ -->
<!-- Generally, we define $\hat{\omega}_1(X_i,X_j) = \hat{\omega}_2(Y_i,Y_j) = 1$, and simplify the notation $\mathbf{BCor}^{2}_{\omega, n}$ as $\mathbf{BCor}^{2}_{n}$ -->
<!-- ![](./BCovPlot.jpeg) -->
<!-- As the image above shown, the joint probability that $X, Y$ are both in the ball are intuitively closed to the product of marginal probability that $X$ and $Y$ are in the ball when $X$ and $Y$ are independent,  i.e.: -->
<!-- $$\Delta_{ij,n}^{X,Y} \approx \Delta_{ij,n}^{X}\Delta_{ij,n}^{Y}$$ -->
<!-- Consequently, if $\mathbf{BCor}_{\omega, n}^{2}$ is significantly larger than 0, then it indicates that $X$ and $Y$ are not independent. -->
<!-- As Pan's paper proved theoretically and demonstrated numerically, the independence test based on $\mathbf{BCor}_{\omega, n}^{2}$ has several advantages: -->
<!-- - It is applicable to the univariate and multivariate data in banach space.       -->
<!-- - Robust to heavy-tail data or outliers         -->
<!-- - Works fine for most problems without tuning a variety of parameters.          -->
<!-- *** -->
</div>
</div>
<div id="advance-features" class="section level1">
<h1 class="hasAnchor">
<a href="#advance-features" class="anchor"></a>Advance Features</h1>
<p>The features below have been implemented to help you analyse diverse and complicated real data.</p>
<div id="non-hilbert-space-data" class="section level2">
<h2 class="hasAnchor">
<a href="#non-hilbert-space-data" class="anchor"></a>Non-Hilbert Space Data</h2>
<p>During the scientific research, we always have to deal with Non-Hilbert space data. However, the traditional statistical inference methods usually depend on some assumptions, which are not able to perform statistical inference on this kind of data directly. Whereas ball divergence doesn’t depend on the assumptions needed in traditional statistical inference method, and it’s able to perform two-sample test for data from Non-Hilbert space. We will demonstrate how to use <strong>Ball</strong> package to perform statistical inference for data from Non-Hilbert space with three examples:</p>
<div id="example-1-simulated-von-mises-fisher-distribution-data" class="section level4">
<h4 class="hasAnchor">
<a href="#example-1-simulated-von-mises-fisher-distribution-data" class="anchor"></a>Example 1: Simulated von Mises-Fisher distribution data</h4>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># load data:</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"bdvmf"</span><span class="op">)</span></code></pre></div>
<p>The distribution of the data is shown in the following image:</p>
<p><img src="BDVmf.png"></p>
<p>In the image, the black dots (<span class="math inline">\(X\)</span>) and red dots (<span class="math inline">\(Y\)</span>) respectively represent two group of simulated data with different distributions. The distributions are denoted by: <span class="math display">\[X \sim M(\mu_{X}, \kappa), Y \sim M(\mu_{Y}, \kappa)\]</span> Where <span class="math inline">\(M\)</span> denotes <a href="https://en.wikipedia.org/wiki/Von_Mises%E2%80%93Fisher_distribution">von Mises-Fisher distribution</a>, <span class="math inline">\(\mu_{X} = (1, 0, 0), \mu_{Y} = (1, 1, 1)\)</span> are the orientation parameter of von Mises-Fisher distribution, <span class="math inline">\(\kappa = 3\)</span> denotes aggregation parameter.</p>
<p>We can tell from the image that, red dots and black dots are not identically distributed. However, it is a tough task for the traditional statistical method to distinguish distribution because it is not a conventional data in Hilbert space. Fortunately, since the computation for sample version of ball divergence (ball covariance) only involves calculate distance matrix and counting the number of samples located in a ball, we can obtain empirical ball divergence so long as we can define the distance metric between observations. Therefore, ball divergence still work for this example.</p>
<p>We apply ball divergence to this data by carrying out the following step. First, we calculate the geodesic distance matrix of the data, which have been implemented in function . Later, we pass the distance matrix to arguments  and let , , and . The detailed solution is demonstrated below:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># calculate geodesic distance between samples:</span>
<span class="va">dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">bdvmf</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"geodesic"</span><span class="op">)</span>
<span class="co"># sample sizes in each group: 150, 150</span>
<span class="co"># Two-Sample Test based on BD :</span>
<span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dx</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">150</span>, <span class="fl">150</span><span class="op">)</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, distance <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   2-sample Ball Divergence Test (Permutation)
# 
# data:  dx 
# number of observations = 300, group sizes: 150 150
# replicates = 99, weight: constant
# bd.constant = 0.14483, p-value = 0.01
# alternative hypothesis: distributions of samples are distinct</code></pre>
<p>In this example, we firstly calculate the geodesic distance matrix using <strong>nhdist</strong> function in <em>Ball</em> package. Then, pass <em>dx</em> to arguments <em>x</em> and set <em>distance = TRUE</em> to indicate that the <em>x</em> parameter is a distance matrix. Meanwhile, we set the size of each sample <em>size = c(150, 150)</em> and set the replication times <em>num.permutations = 99</em>. The result is that <em>p</em>-value &lt; 0.05, which means that red dots and black dots are not identically distributed.</p>
</div>
<div id="example-2-macaques-data" class="section level4">
<h4 class="hasAnchor">
<a href="#example-2-macaques-data" class="anchor"></a>Example 2: Macaques Data</h4>
<p>Based on Macaques data provided by dryden, scientists want to figure out whether there are differences in the shape of skull between Macaques of different genders. In a similar way, we can calculate the distance matrix of the data and transform this problem into two-sample test that can be solved by BD. Riemann shape distance is always used to describe the distance between shape data. By setting <em>method = “riemann”</em> in the <strong>nhdist</strong> function, we are able to calculate the riemann shape distance between shape data. The detailed procedure is demonstrated below:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># load data:</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"macaques"</span><span class="op">)</span>
<span class="co"># number of femala and male Macaca fascicularis:</span>
<span class="co"># table(macaques[["group"]])  # f: 9; m: 9</span>
<span class="co"># calculate Riemannian shape distance matrix:</span>
<span class="va">dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">macaques</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"riemann"</span><span class="op">)</span>
<span class="co"># hypothesis test with BD:</span>
<span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dx</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">9</span>, <span class="fl">9</span><span class="op">)</span>, distance <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   2-sample Ball Divergence Test (Permutation)
# 
# data:  dx 
# number of observations = 18, group sizes: 9 9
# replicates = 99, weight: constant
# bd.constant = 0.1922, p-value = 0.03
# alternative hypothesis: distributions of samples are distinct</code></pre>
<p><em>p</em>-value is under 0.05, which means the skull shape differs between male macaques and female macaques.</p>
</div>
<div id="example-3-arcticlake-data" class="section level4">
<h4 class="hasAnchor">
<a href="#example-3-arcticlake-data" class="anchor"></a>Example 3: ArcticLake Data</h4>
<p><strong>bcov.test</strong> is related to calculating the distance between samples of two multivariate random variables. Therefore, we can examine independence assumption by employing <strong>bcov.test</strong> to non-Hilbert space real data so long as we obtain the distance matrix of the samples.</p>
<p>We take a data in the Book, <strong>The Statistical Analysis of Compositional Data</strong>, as an example to demonstrate how to use <strong>bcov.test</strong> to determine the dependence of non-Hilbert space data. Scientists collect Sand, silt and clay compositions of 39 sediment samples of different water depth in an Arctic lake. They want to figure out whether the compositions of sediment samples of different water depth are identical or not. To achieve the goal, we use <strong>bcov.test</strong> to perform the test of independence. The detailed procedure is demonstrated below:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"ArcticLake"</span><span class="op">)</span>
<span class="co"># Distance matrix between y:</span>
<span class="va">dy</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"compositional"</span><span class="op">)</span>
<span class="co"># Distance matrix between x:</span>
<span class="va">dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"depth"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="co"># hypothesis test with BCov:</span>
<span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dx</span>, y <span class="op">=</span> <span class="va">dy</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, distance <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   Ball Covariance test of independence (Permutation)
# 
# data:  dx and dy
# number of observations = 39
# replicates = 99, weight: constant
# bcov.constant = 0.0083848, p-value = 0.01
# alternative hypothesis: random variables are dependent</code></pre>
<p>We first calculate the distance matrix <em>dy</em> and <em>dx</em>. Then, we pass <em>dx</em> to arguments <em>x</em>, <em>dy</em> to arguments <em>y</em>, and set the replication times <em>num.permutations = 99</em>, <em>distance = TRUE</em> to indicate that the <em>x</em> and <em>y</em> parameters are distance matrices.<br>
The result shows that <em>p</em>-value is less than 0.05, an usual significance level, so we conclude that the compositions of sediment is associated with the water depth.</p>
<p>In the example above, we use the square root transformed data to calculate the geodesic distance as a measurement of the difference between different compositions of sediment samples (<em>Dy</em>). Meanwhile, we use euclidean distance to measure the difference of different water depth (<em>Dx</em>). For different data, we can use different measurements to cope with the different features in data.</p>
</div>
</div>
<div id="k-sample-test" class="section level2">
<h2 class="hasAnchor">
<a href="#k-sample-test" class="anchor"></a>K-Sample Test</h2>
<p><strong>bd.test</strong> is also applicable for testing of multiple samples. We generate three random normal samples of size 50, which are sampled from the same normal distribution. As an example, we use <strong>bd.test</strong> to test whether these samples are identically distributed.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">150</span>
<span class="fu"><a href="../reference/bd.test.html">bd.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>, size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   3-sample Ball Divergence Test (Permutation)
# 
# data:  rnorm(n) 
# number of observations = 150, group sizes: 50 50 50
# replicates = 99, weight: constant, kbd.type: sum
# kbd.sum.constant = 0.048994, p-value = 0.34
# alternative hypothesis: distributions of samples are distinct</code></pre>
<p>As the result shown, <em>p</em>-value&gt;0.05, which means we can’t reject the null hypothesis.<br>
We can also utilize <strong>bd.test</strong> to deal with <span class="math inline">\(K\)</span>-Sample problem in non-Hilbert space following the aforementioned procedure. At the same time, remember to assign size vector to parameter <em>size</em> arguments and set <em>distance = TRUE</em>.</p>
<!-- Independent test based on ball correlation, which is a normalized coefficient of ball covariance also available now. Ball correlation statistic will be used when setting  -->
<!-- *type = "Bcor"* in **bcov.test**.          -->
</div>
<div id="weighted-ball-covariance-test" class="section level2">
<h2 class="hasAnchor">
<a href="#weighted-ball-covariance-test" class="anchor"></a>Weighted Ball Covariance Test</h2>
<!-- Moreover, we can extend defintion of $\hat{\omega}_1(X_i,X_j), \hat{\omega}_2(Y_i,Y_j)$. For example, we let: -->
<!-- $$\hat{\omega}_1(X_i,X_j) = \frac{1}{\rho(X_{i}, X_{j})}, \hat{\omega}_2(Y_i,Y_j) = \frac{1}{\rho(Y_{i}, Y_{j})}$$ -->
<!-- and calculate the weighted ball covariance:         -->
<!-- $$\mathbf{BCov}^2_{\omega,n}(\mathbf{X},\mathbf{Y}):=\frac{1}{n^2}\sum_{i,j=1}^{n}{(\Delta_{ij,n}^{X,Y}-\Delta_{ij,n}^{X}\Delta_{ij,n}^{Y})^2\hat{\omega}_1(X_i,X_j)\hat{\omega}_2(Y_i,Y_j)}$$ -->
<p>Pan et. al(2017) show that the weighted ball covariance based independence test is statistical consistent against all dependence alternatives without any moment conditions and some times superior to standard version of ball covariance.</p>
<p>We have been implemented weighted ball covariance test in <strong>Ball</strong> package and we can employ it to data analysis by just setting <em>weight = TRUE</em> in <strong>bcov.test</strong>. Take <em>ArcticLake</em> data as example:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"ArcticLake"</span><span class="op">)</span>
<span class="va">Dy</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nhdist.html">nhdist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span>, method <span class="op">=</span> <span class="st">"compositional"</span><span class="op">)</span>
<span class="va">Dx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="va">ArcticLake</span><span class="op">[[</span><span class="st">"depth"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="co"># hypothesis test with weighted BCov:</span>
<span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Dx</span>, y <span class="op">=</span> <span class="va">Dy</span>, num.permutations <span class="op">=</span> <span class="fl">99</span>, 
          distance <span class="op">=</span> <span class="cn">TRUE</span>, weight <span class="op">=</span> <span class="st">"constant"</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   Ball Covariance test of independence (Permutation)
# 
# data:  Dx and Dy
# number of observations = 39
# replicates = 99, weight: constant
# bcov.constant = 0.0083848, p-value = 0.01
# alternative hypothesis: random variables are dependent</code></pre>
</div>
<div id="ball-covariance-mutual-independence-test" class="section level2">
<h2 class="hasAnchor">
<a href="#ball-covariance-mutual-independence-test" class="anchor"></a>Ball Covariance Mutual Independence Test</h2>
<p>Apart from the relationships between two random variables, another important dependence concept for a set of variables is mutual (or joint) independence, which says that any two disjoint subsets of variables are independent from each other. For instance, we know to investigate whether air temperature, soil temperature, humidity, wind and evaporation are correlated.</p>
<p>It is natural to extend ball covariance to measure mutual independence between <span class="math inline">\(K\)</span> random variables. <!-- as follows: --> <!-- $$\mathbf{BCor}_{\omega, n}^{2}(R_{1}, ..., R_{K})=\frac{1}{n^{2}}\sum_{i,j=1}^{n}{(\Delta_{ij,n}^{R_{1}, ..., R_{K}}-\prod_{k=1}^{K}\Delta_{ij,n}^{R_{k}})^{2}\prod_{k=1}^{K}{\hat{\omega}_{k}(R_{ki},R_{kj})}}$$ --> <!-- where $R_{k}, k=1,...K$ indicate random variables and $R_{ki}, i=1,...,n$ denote $n$ random samples of $R_{k}$.  --> More importantly, Mutual independence test based on ball covariance have been implemented in <strong>Ball</strong> package. We give two simply example in the following to demonstrate its usage.</p>
<p>The first example, <span class="math inline">\(X, \epsilon_{1}, \epsilon_{2}\)</span> are independent from the standard normal distribution <span class="math inline">\(N(0,1)\)</span>, and <span class="math display">\[Y = \max(X, 0) + \epsilon_{1}, \; Z = \min(X, 0) + \epsilon_{2}\]</span></p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>
<span class="va">z</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>
<span class="va">example1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">z</span><span class="op">)</span></code></pre></div>
<p>The Second example, <span class="math inline">\(W, X, Y, Z\)</span> are connected by a latent random variable <span class="math inline">\(H \sim N(0,1)\)</span>, and <span class="math display">\[W = H^{2}; X = |H|, Y = min(H, 0)\]</span> <span class="math display">\[Z = (Z_{1}, Z_{2}), Z_{1}=I(H&lt;0.5)H, Z_{2}=I(H&gt;-0.5)H\]</span></p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>
<span class="va">w</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">h</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">h</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="va">h</span> <span class="op">*</span> <span class="op">(</span><span class="va">h</span> <span class="op">&lt;</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">z1</span> <span class="op">&lt;-</span> <span class="va">h</span> <span class="op">*</span> <span class="op">(</span><span class="va">h</span> <span class="op">&lt;</span> <span class="fl">0.5</span><span class="op">)</span>
<span class="va">z2</span> <span class="op">&lt;-</span> <span class="va">h</span> <span class="op">*</span> <span class="op">(</span><span class="va">h</span> <span class="op">&gt;</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span>
<span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">z1</span>, <span class="va">z2</span><span class="op">)</span>
<span class="va">example2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">w</span>, <span class="va">x</span>, <span class="va">y</span>, <span class="va">z</span><span class="op">)</span></code></pre></div>
<p>We bind these data to list <em>example1</em> and <em>example2</em> and pass them to arguments <em>x</em> in <strong>bcov.test</strong> to carry out ball covariance mutual independence test.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">example1</span>, num.permutations <span class="op">=</span> <span class="fl">199</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   Ball Covariance test of mutual independence (Permutation)
# 
# data:  example1
# number of observations = 50
# replicates = 199, weight: constant
# bcov.constant = 0.0014947, p-value = 0.03
# alternative hypothesis: random variables are dependent</code></pre>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bcov.test.html">bcov.test</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">example2</span>, num.permutations <span class="op">=</span> <span class="fl">199</span><span class="op">)</span></code></pre></div>
<pre><code># 
#   Ball Covariance test of mutual independence (Permutation)
# 
# data:  example2
# number of observations = 50
# replicates = 199, weight: constant
# bcov.constant = 0.037093, p-value = 0.005
# alternative hypothesis: random variables are dependent</code></pre>
<p>The hypothesis test result for two examples show that <em>p</em>-value &lt; 0.05, coinciding with the simulation setting.</p>
</div>
<div id="ball-correlation-based-sure-independence-screening" class="section level2">
<h2 class="hasAnchor">
<a href="#ball-correlation-based-sure-independence-screening" class="anchor"></a>Ball Correlation Based Sure Independence Screening</h2>
<p>Recent technological advances have made it possible to collect ultra high-dimensional data. A common feature of these data is that the number of variables <span class="math inline">\(p\)</span> is generally much larger than sample sizes <span class="math inline">\(n\)</span>. For instance, the number of gene expression profiles is in the order of tens of thousands while the number of patient samples is in the order of tens or hundreds. However, traditional variable selection algorithms such as LASSO, SCAD may not perform well due to the statistical inaccuracy, and algorithmic instability.</p>
<p>A new framework, sure independence screening (SIS), was proposed to tackle the challenges above. SIS tries to filtering out the features that have marginal correlation with the response, hence effectively reducing the dimensionality <span class="math inline">\(p\)</span> to a moderate scale so that performing statistical algorithm is feasible.</p>
<p>BCor-SIS, a generic non-parametric sure independence screening procedure based on ball correlation, is able to pick out explanatory variables related to response. The linear, non-linear or linear interaction effect relationship can be captured by BCor-SIS even though data is heavy tail or existing outliers. More importantly, BCor-SIS is able to retain all of the important features in the model with probability tending to 1 under mild conditions.</p>
<div id="bcor-sis-quick-start-example" class="section level3">
<h3 class="hasAnchor">
<a href="#bcor-sis-quick-start-example" class="anchor"></a>BCor-SIS: Quick Start Example</h3>
<p>In this example, we will utilize <strong>bcorsis</strong> function to carry out BCor-SIS procedure. We generate 150 high dimensional instances with 3000 independent standard gaussian explanatory variables <span class="math inline">\(X\)</span> and univariate response variable <span class="math inline">\(Y\)</span>. The relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is:<br><span class="math display">\[Y=3 X_{1} + 5 X_{3}^{2} + \epsilon, \quad \epsilon \sim N(0, 1)\]</span></p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">150</span>
<span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">3000</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span><span class="op">)</span>
<span class="va">noise</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">3</span><span class="op">*</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fl">5</span><span class="op">*</span><span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">noise</span></code></pre></div>
<p>We perform BCor-SIS procedure and display the top 5 variables index selected by BCor-SIS.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bcorsis.html">bcorsis</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, x <span class="op">=</span> <span class="va">x</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">res</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>, n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></code></pre></div>
<pre><code># [1]    3    1 1601   20  429</code></pre>
<p>The <strong>bcorsis</strong> result shows that the first and the third variable are the two most important variables in 3000 explanatory variables which is consistent to simulation settings.</p>
</div>
<div id="extension-of-bcor-sis-a-censored-survival-data" class="section level3">
<h3 class="hasAnchor">
<a href="#extension-of-bcor-sis-a-censored-survival-data" class="anchor"></a>Extension of BCor-SIS: A Censored Survival Data</h3>
<p>Survival analysis is a commonly used method for the analysis of censored data such as biological death and mechanical failure, which is usually subject to censoring. The main goal of survival analysis is to study the dependence of the survival time <span class="math inline">\(T\)</span> on covariate variables <span class="math inline">\(X, X \in R^{p}\)</span>.</p>
<p>With the remarkable development of modern technology, a huge amount of covariate information such as microarray and SNP data are collected. Consequently, SIS procedure designed for censored survival data is in need. Pan et al(2017) proposed a extend BCor-SIS procedure which is able to selected the significant variables for censored data.</p>
<p>We implement BCor-SIS procedure for survival data in <strong>Ball</strong> package and use a publicly lung cancer genomic data from the Chemores Cohort Study to demonstrate its usage. The data outcome was the “Disease-Free Survival Time”. Patients were followed until the first relapse occurred or administrative censoring. In this genomic dataset, the expression levels of mRNA, miRNA as well as clinical variables from the 123 samples were included. Moreover, this dataset include 944 biological covariates and 1056 artificial standard gaussian variables which are independence with response. We employ extension of Bcor-SIS on this data to hunt for efficient covariates and demonstrate detailed procedure in the following.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bcorsis.html">bcorsis</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">genlung</span><span class="op">[[</span><span class="st">"covariate"</span><span class="op">]</span><span class="op">]</span>, 
                  y <span class="op">=</span> <span class="va">genlung</span><span class="op">[[</span><span class="st">"survival"</span><span class="op">]</span><span class="op">]</span>, 
                  d <span class="op">=</span> <span class="st">"small"</span>, method <span class="op">=</span> <span class="st">"survival"</span><span class="op">)</span>
<span class="va">top_gene</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">genlung</span><span class="op">[[</span><span class="st">"covariate"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">[</span><span class="va">result</span><span class="op">[[</span><span class="st">"ix"</span><span class="op">]</span><span class="op">]</span><span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">top_gene</span>, n <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<pre><code># [1] "hsa.miR.564"</code></pre>
<p>We first pass covariates and censored information to arugments <em>x</em> and <em>y</em>, and set the <em>method = “survival”</em> to indicate that the <em>y</em> should be considered as a survival status containing event time and censored status. BCor-SIS asserts that <em>hsa.miR.564</em>, corresponding to gene <em>MIR564</em>, is strongly relevant to disease-free survival status. The conclusion is highly coincident with the statement in other public literature.</p>
<!-- ### Reference -->
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Jin Zhu, Wenliang Pan, Heping Zhang, Hongtu Zhu, Yuan Tian, Weinan Xiao, Chengfeng Liu, Ruihuang Liu, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
